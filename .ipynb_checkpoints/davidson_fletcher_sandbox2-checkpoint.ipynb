{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imlement LDA\n",
    "\n",
    "#What is the difference between the four different embedding_creators?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim\n",
    "# pip install --upgrade gensim\n",
    "# pip install sklearn\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'short_data/'\n",
    "just_one_test_file = 'short_data/Tolkein/fotr_short2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_simplifier(one_file_path, document_length=100):\n",
    "    \"\"\"\n",
    "    :Purpose: To take a filepath and return a cleaned string of all the text contained inside.  This is not a complete pre-processing or tokenization.  \n",
    "    \n",
    "    \n",
    "    :param one_file_path: a string which is a path to one file where text is stored. \n",
    "    :type one_file_path: string\n",
    "\n",
    "    :param document_length: default = 100, this integer determines the number of words in each document\n",
    "    :type document_length: int\n",
    "    \n",
    "    :return: all the text from the file without any extra whitespace, newlines, headers, etc. separated out into lists, each of which contains three sentences with words returned as separate strings. \n",
    "    :return type: list of lists of strings\n",
    "    \"\"\"\n",
    "    \n",
    "    # A regex to keep only the alphabetical characters.\n",
    "    #stripper = re.compile('[^a-zA-Z\\.]') # Use to keep periods in\n",
    "    stripper = re.compile('[^a-zA-Z]')  # Use to remove periods also \n",
    "    lines = [line.rstrip('\\n') for line in open(one_file_path)]\n",
    "    stripped_lines = []\n",
    "    for line in lines:\n",
    "        stripped_line = stripper.sub(' ', line)\n",
    "        stripped_lines.append(stripped_line)\n",
    "    stripped_lines = stripped_lines[10:]\n",
    "\n",
    "    cleaned_lines = list(filter(lambda x: x != ' uc  u      ', stripped_lines))\n",
    "    combined_clean = ' '.join(cleaned_lines)\n",
    "    white_stripped_clean = ' '.join(combined_clean.split())\n",
    "    to_lower = white_stripped_clean.lower()\n",
    "    no_stopwords = remove_stopwords(to_lower)\n",
    "    preprocessed = simple_preprocess(no_stopwords,deacc=False)\n",
    "#    print(type(preprocessed[0]))\n",
    "#    print(preprocessed)\n",
    "    documents = [preprocessed[i:i+document_length] for i in range(0,len(preprocessed), document_length)]\n",
    "\n",
    "    return documents\n",
    "\n",
    "#text_simplifier(just_one_test_file, document_length=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_text(data_path):\n",
    "    \"\"\"\n",
    "    :Purpose: To run text_simplifier on all text files within a directory\n",
    "    \n",
    "    \n",
    "    :param data_path: a string which is a path to a  file where text is stored. \n",
    "    :type data_path: string\n",
    "    \n",
    "    :return: all the text from all the files without any extra whitespace, newlines, headers, etc. Each file becomes a string in a list\n",
    "    :return type: list of lists of strings\n",
    "    \"\"\"\n",
    "    total_text = []\n",
    "    for filename in os.listdir(data_path):\n",
    "        if (filename != \".DS_Store\"):\n",
    "            print(f\"Importing from file: {filename}\")\n",
    "            text_of_one_file = text_simplifier(data_path+filename, document_length=100)            \n",
    "            total_text.append(text_of_one_file)\n",
    "    #total_text_joined = [sublist.join() for sublist in total_text]\n",
    "    total_text_joined = [j for i in total_text for j in i]\n",
    "#    observations = pd.DataFrame({'documents': total_text_joined, 'author' : data_path})\n",
    "#    observations['preprocessed']= observations['documents'].apply(simple_preprocess)\n",
    "#    print(observations)\n",
    "    \n",
    "    return total_text_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_model(data_folder, filename):\n",
    "    \"\"\"\n",
    "    :Purpose: create an embedding from a set of text data, Save the embedding as a correctly named model\n",
    "    \n",
    "    \n",
    "    :param data_folder: a string which is a path to a folder where text is stored. \n",
    "    :type data_folder: string\n",
    "    \n",
    "    :param filename: the sub_folder containing a particular author's works. \n",
    "    :type filename: string\n",
    "\n",
    "    :return: returns a gensim embedding layer which represents every distinct word in a corpus as a vector of length \"size\" \n",
    "    :return type: gensim.models.word2vec.Word2Vec\n",
    "    \"\"\"\n",
    "    \n",
    "    data_path = data_folder+filename+'/'\n",
    "    # define training data\n",
    "    documents = get_all_text(data_path)\n",
    "#    sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "#\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
    "#\t\t\t['yet', 'another', 'sentence'],\n",
    "#\t\t\t['one', 'more', 'sentence'],\n",
    "#\t\t\t['and', 'the', 'final', 'sentence']]\n",
    "    # train model\n",
    "    bigram_transformer = Phrases(documents)\n",
    "    bigrams = Phraser(bigram_transformer)\n",
    "    model = Word2Vec(bigrams[documents], sg=1, size=100, window=5, min_count=1, workers=4)\n",
    "    # sg = 1 gives us skip-gram\n",
    "    # Size gives us the length of the embedding\n",
    "    # Window is \"The maximum distance between the current and predicted word within a sentence\" which I believe is the skip size. \n",
    "    # min_count (int) â€“ Ignores all words with total frequency lower than this\n",
    "\n",
    "    # summarize the loaded model\n",
    "    print(model)\n",
    "    # summarize vocabulary\n",
    "#    words = list(model.wv.vocab)\n",
    "#    print(words)\n",
    "    # access vector for one word\"\n",
    "#    print(model['river'])\n",
    "    # save model\n",
    "    model.save('model_'+filename+'.bin')\n",
    "    # load model\n",
    "#    new_model = Word2Vec.load('model.bin')\n",
    "#    print(new_model)\n",
    "#    return mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model for Austen:\n",
      "\n",
      "Importing from file: austen_short1.txt\n",
      "Importing from file: austen_short2.txt\n",
      "Word2Vec(vocab=492, size=100, alpha=0.025)\n",
      "\n",
      "Creating a model for Tolkein:\n",
      "\n",
      "Importing from file: fotr_short1.txt\n",
      "Importing from file: fotr_short2.txt\n",
      "Word2Vec(vocab=261, size=100, alpha=0.025)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_all_models(data_folder):\n",
    "    \"\"\"\n",
    "    :Purpose: To create embeddings from all the authors whose works are in the folder, \n",
    "    save all the embeddings with appropriate filenames and return a list of the authors \n",
    "    whose work has been used. \n",
    "    \n",
    "    :param data_folder: a string which is a path to a folder where text is stored. \n",
    "    :type data_folder: string\n",
    "    \n",
    "    :return: a list of the authors whose works have been made into embeddings\n",
    "    :return type:  list of strings\n",
    "    \"\"\"\n",
    "    authors_list = []\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if (filename != \".DS_Store\"):\n",
    "            print(f\"Creating a model for {filename}:\")\n",
    "            print()\n",
    "            create_and_save_model(data_folder, filename)\n",
    "            print()\n",
    "            authors_list.append(filename)\n",
    "    return authors_list\n",
    "list_of_authors = create_all_models(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_model_dictionary_generator(list_of_authors):\n",
    "    \"\"\"\n",
    "    :Purpose: To create a dictionary of all the various author embeddings with the authors as the keys.\n",
    "    \n",
    "    :param list_of_authors: the list of different embeddings \n",
    "    :type list_of_authors: list of strings\n",
    "    \n",
    "    :return: a python dictionary with author names as keys and embeddings created from their work as contents\n",
    "    :return type: python dictionary \n",
    "    \"\"\"\n",
    "\n",
    "    model_list = []\n",
    "    for author_index in range(0,len(list_of_authors)):\n",
    "        one_model = Word2Vec.load('model_'+list_of_authors[author_index]+'.bin')\n",
    "        model_list.append(one_model)\n",
    "    author_model_dictionary = dict(zip(list_of_authors, model_list))\n",
    "    return author_model_dictionary\n",
    "author_model_dictionary = author_model_dictionary_generator(list_of_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('britain', 0.2710121273994446),\n",
       " ('hot', 0.2630371153354645),\n",
       " ('printed', 0.22703707218170166),\n",
       " ('shakespeare', 0.21296140551567078),\n",
       " ('scarcely', 0.21065479516983032),\n",
       " ('reforms', 0.1994336098432541),\n",
       " ('fate', 0.1944923996925354),\n",
       " ('windless', 0.19445110857486725),\n",
       " ('issue', 0.19081830978393555),\n",
       " ('dexterity', 0.18965721130371094)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_model_dictionary['Austen'].wv.most_similar('pleased')\n",
    "author_model_dictionary['Austen'].wv.most_similar(negative=['pleased'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a159fcb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PCA_scatter(model):\n",
    "\n",
    "    # fit a 2d PCA model to the vectors\n",
    "    X = model[model.wv.vocab]\n",
    "    pca = PCA(n_components=2)\n",
    "    result = pca.fit_transform(X)\n",
    "    # create a scatter plot of the projection\n",
    "    pyplot.scatter(result[45:60, 0], result[45:60, 1])\n",
    "    words = list(model.wv.vocab)\n",
    "    for i, word in enumerate(words[45:60]): # This has been changed so we only show 20 labels. \n",
    "        pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "    pyplot.show()\n",
    "\n",
    "    \n",
    "PCA_scatter(author_model_dictionary['Austen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ac0fa6b02300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mPCA_for_specific_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-ac0fa6b02300>\u001b[0m in \u001b[0;36mPCA_for_specific_words\u001b[0;34m(list_of_specific_words)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mPCA_for_specific_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_specific_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mspecific_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_specific_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "characters = ['Frodo', 'Sam', 'Aragorn', 'Elrond']\n",
    "\n",
    "def PCA_for_specific_words(list_of_specific_words):\n",
    "    vocab = list(model.wv.vocab)\n",
    "    specific_words = list(filter(lambda x: x in list_of_specific_words, vocab))\n",
    "\n",
    "    X = model[specific_words]\n",
    "    cluster_num = 3\n",
    "\n",
    "    kmeans = KMeans(n_clusters=cluster_num, random_state=42).fit(X)\n",
    "    cluster = kmeans.predict(X)\n",
    "\n",
    "    pca = PCA(n_components=2, random_state=42, whiten=True)\n",
    "    clf = pca.fit_transform(X)\n",
    "    tmp = pd.DataFrame(clf, index=specific_words, columns=['x', 'y'])\n",
    "\n",
    "    pyplot.scatter(clf[:, 0], clf[:, 1])\n",
    "    for i, word in enumerate(specific_words):\n",
    "        pyplot.annotate(word, xy=(clf[i, 0], clf[i, 1]))\n",
    "    pyplot.show()\n",
    "    \n",
    "PCA_for_specific_words(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_LDA = 'data/Tolkein/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_one_test_file_LDA = 'short_data/Tolkein/fotr_short2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing from file: fotr_short1.txt\n",
      "Importing from file: fotr_short2.txt\n"
     ]
    }
   ],
   "source": [
    "documents_for_LDA = get_all_text(data_folder_LDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_documents = [\" \".join(sublist) for sublist in documents_for_LDA]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA\n",
    "#data_documents needs to be a list of strings\n",
    "# Brendan's code for LDA is here:\n",
    "# https://github.com/thisismetis/sf18_ds10/blob/master/class_lectures/week07-fletcher1/05-quiz_labs/LDA.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Document Preprocessing\n",
    "We'll need to generate a term-document matrix of word (token) counts for use in LDA.\n",
    "\n",
    "We'll use sklearn's CountVectorizer to generate our term-document matrix of counts. We'll make use of a few parameters to accomplish the following preprocessing of the text documents all within the CountVectorizer:\n",
    "\n",
    "analyzer=word: Tokenize by word\n",
    "ngram_range=(1,2): Keep all 1 and 2-word grams\n",
    "stop_words=english: Remove all English stop words\n",
    "token_pattern=\\\\b[a-z][a-z]+\\\\b: Match all tokens with 2 or more (strictly) alphabet characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='\\\\b[a-z][a-z]+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a CountVectorizer for parsing/counting words\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2),  \n",
    "                                   stop_words='english', token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "count_vectorizer.fit(data_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the term-document matrix\n",
    "# Transpose it so the terms are the rows\n",
    "counts = count_vectorizer.transform(data_documents).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to gensim\n",
    "We need to convert our sparse scipy matrix to a gensim-friendly object called a Corpus. This is also essential for term-document matrices that are larger than local memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix of counts to a gensim corpus\n",
    "corpus = matutils.Sparse2Corpus(counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map matrix rows to words (tokens)\n",
    "We need to save a mapping (dict) of row id to word (token) for later use by gensim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict((v, k) for k, v in count_vectorizer.vocabulary_.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "At this point, we can create an LDA model. It requires our corpus of word counts, mapping of row ids to words, and our selection of num_topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lda model (equivalent to \"fit\" in sklearn)\n",
    "lda = models.LdaModel(corpus=corpus, num_topics=5, minimum_probability=0.03, id2word=id2word, passes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"gone\" + 0.012*\"elrond\" + 0.008*\"far\" + 0.008*\"north\" + 0.008*\"pass\" + 0.008*\"river\" + 0.008*\"passing\" + 0.008*\"gladden\" + 0.008*\"return\" + 0.008*\"old\"'),\n",
       " (1,\n",
       "  '0.015*\"shadow\" + 0.015*\"know\" + 0.008*\"said\" + 0.008*\"far\" + 0.008*\"elrond\" + 0.008*\"mountains\" + 0.008*\"come\" + 0.008*\"way\" + 0.008*\"lands\" + 0.008*\"feet\"'),\n",
       " (2,\n",
       "  '0.012*\"frodo\" + 0.012*\"said\" + 0.012*\"black\" + 0.008*\"far\" + 0.008*\"enemy\" + 0.008*\"time\" + 0.008*\"ring\" + 0.008*\"seen\" + 0.004*\"hobbits\" + 0.004*\"mountains\"'),\n",
       " (3,\n",
       "  '0.002*\"gone\" + 0.002*\"far\" + 0.002*\"elrond\" + 0.002*\"mountains\" + 0.002*\"return\" + 0.002*\"said\" + 0.002*\"enemy\" + 0.002*\"north\" + 0.002*\"come\" + 0.002*\"journey\"'),\n",
       " (4,\n",
       "  '0.008*\"said\" + 0.008*\"frodo\" + 0.008*\"brighter\" + 0.008*\"good\" + 0.008*\"moon\" + 0.008*\"shone\" + 0.008*\"night\" + 0.004*\"hope\" + 0.004*\"hobbits\" + 0.004*\"journey\"')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's take a look at what happened. Here are the 5 most important words for each topic we found:\n",
    "lda.print_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x104627710>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the docs from the word space to the topic space (like \"transform\" in sklearn)\n",
    "lda_corpus = lda[corpus]\n",
    "lda_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the documents' topic vectors in a list so we can take a peak\n",
    "lda_docs = [doc for doc in lda_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the document vectors in the topic space, which are measures of the component of each document along each topic. Thus, at most a document vector can have num_topics=3 nonzero components in the topic space, and most have far fewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(4, 0.99599564)],\n",
       " [(0, 0.9959941)],\n",
       " [(2, 0.9959927)],\n",
       " [(1, 0.9899888)],\n",
       " [(4, 0.99599564)],\n",
       " [(0, 0.9959941)],\n",
       " [(2, 0.9959927)],\n",
       " [(1, 0.9899888)]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the document vectors in the topic space for the first 5 documents\n",
    "lda_docs[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.290028649233502"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can quantify the 'fit' of our model, to compare with other corpora, etc.# we ca \n",
    "lda.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower perplexity is better, but the practical utility of LDA is the final word in how happy we are with our model:\n",
    "\n",
    "Is it intuitively associating my documents with my themes?\n",
    "\n",
    "Is it helping me cluster similar documents together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
